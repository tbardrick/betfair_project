{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betfair Historical Data large dataset creation\n",
    "1. Following `2_betfair_advanced_data_test.ipynb` steps to download historical data\n",
    "2. Iterating the stream through a list of files to create a dataset containing multiple events and race days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the Betfair API through betfairlightweight, you must have first set up your API certificates and saved the login details in dictionary format in a file called `api_logins.json` in the project home directory (`/betfair_project`). The following connects and should return `<LoginResource>` if successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LoginResource>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import betfairlightweight\n",
    "from betfairlightweight import filters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path, PurePath #To define open and save locations that are cross-compatible between Windows/Linux\n",
    "from bz2 import BZ2File #To unzip the Betfair data from its downloaded format\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project_dir = Path.cwd().parents[1]\n",
    "logins_dir = project_dir / 'api_logins.json'\n",
    "\n",
    "with open(logins_dir) as f:\n",
    "    login_dict =  json.load(f)\n",
    "    \n",
    "trading = betfairlightweight.APIClient(username=login_dict['my_username'],\n",
    "                                       password=login_dict['my_password'],\n",
    "                                       app_key=login_dict['my_app_key'],\n",
    "                                       certs=login_dict['certs_path'])\n",
    "\n",
    "trading.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the following, you must have purchased data from the [Betfair Historical data service](https://historicdata.betfair.com/#/home). Advanced data for all sports has been offered for free for Jan - May 2020. To understand more about what different packages of data include, look in the data dictionaries folder in this project. The following lists the data that you have purchased on your Betfair account. Since data is purchased by month, that is how it is represented here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-01-01T00:00:00', 'purchaseItemId': 42364}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-02-01T00:00:00', 'purchaseItemId': 42364}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-03-01T00:00:00', 'purchaseItemId': 42364}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-04-01T00:00:00', 'purchaseItemId': 41549}\n",
      "{'sport': 'Horse Racing', 'plan': 'Advanced Plan', 'forDate': '2020-05-01T00:00:00', 'purchaseItemId': 41549}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2016-01-01T00:00:00', 'purchaseItemId': 25202}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2017-06-01T00:00:00', 'purchaseItemId': 770}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-01-01T00:00:00', 'purchaseItemId': 24527}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2018-02-01T00:00:00', 'purchaseItemId': 24527}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2019-03-01T00:00:00', 'purchaseItemId': 28609}\n",
      "{'sport': 'Horse Racing', 'plan': 'Basic Plan', 'forDate': '2019-12-01T00:00:00', 'purchaseItemId': 25201}\n",
      "{'sport': 'Horse Racing', 'plan': 'Pro Plan', 'forDate': '2020-04-01T00:00:00', 'purchaseItemId': 42365}\n",
      "{'sport': 'Horse Racing', 'plan': 'Pro Plan', 'forDate': '2020-05-01T00:00:00', 'purchaseItemId': 42365}\n"
     ]
    }
   ],
   "source": [
    "my_data = trading.historic.get_my_data()\n",
    "for i in my_data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following selects just the data for from 01/01/20 to 01/03/20 and returns a dictionary of the contents of the data which we go on to use to download specific country/race/market types, and tells us the size of the entire selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'marketTypesCollection': [{'name': '', 'count': 1998}, {'name': 'ANTEPOST_WIN', 'count': 22}, {'name': 'DAILY_WIN_DIST', 'count': 1}, {'name': 'EACH_WAY', 'count': 1788}, {'name': 'FORECAST', 'count': 438}, {'name': 'MATCH_BET', 'count': 1692}, {'name': 'OTHER_PLACE', 'count': 4746}, {'name': 'PLACE', 'count': 9161}, {'name': 'RACE_WIN_DIST', 'count': 175}, {'name': 'REV_FORECAST', 'count': 784}, {'name': 'WIN', 'count': 11923}, {'name': 'WITHOUT_FAV', 'count': 306}], 'countriesCollection': [{'name': 'AE', 'count': 511}, {'name': 'AU', 'count': 11874}, {'name': 'ES', 'count': 6}, {'name': 'FR', 'count': 549}, {'name': 'GB', 'count': 10230}, {'name': 'HK', 'count': 1}, {'name': 'IE', 'count': 2147}, {'name': 'NZ', 'count': 2016}, {'name': 'SA', 'count': 44}, {'name': 'SG', 'count': 314}, {'name': 'US', 'count': 4038}, {'name': 'ZA', 'count': 1304}], 'fileTypeCollection': [{'name': 'E', 'count': 1998}, {'name': 'M', 'count': 31036}]}\n",
      "{'totalSizeMB': 5731, 'fileCount': 33034}\n"
     ]
    }
   ],
   "source": [
    "collection_options = trading.historic.get_collection_options(\n",
    "    \"Horse Racing\", \"Advanced Plan\", 1, 1, 2020, 1, 3, 2020\n",
    ")\n",
    "\n",
    "print(collection_options)\n",
    "\n",
    "basket_size = trading.historic.get_data_size(\n",
    "    \"Horse Racing\", \"Advanced Plan\", 1, 1, 2020, 1, 3, 2020\n",
    ")\n",
    "print(basket_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dig into particular dates, countries, race types and market types we use `.get_file_list()`, specifying our filtering parameters. For example, you can see above that within the sub-dictionary for `'marketTypesCollection'` we have `'WIN'`, among others. The following retrieves a list of the event files that match these parameters. We select only data for 01/02/20, for the `'WIN'` market only and in `'GB'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130661.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096552.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136214.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133543.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130666.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096559.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136219.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130671.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133548.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096566.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136224.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133553.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130676.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168130245.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136229.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133558.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130681.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096580.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136234.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130686.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133563.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096587.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136239.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133568.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130691.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096594.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136244.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133573.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133491.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133496.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133501.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133506.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133511.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133516.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133521.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133526.bz2']\n"
     ]
    }
   ],
   "source": [
    "file_list = trading.historic.get_file_list(\n",
    "    \"Horse Racing\",\n",
    "    \"Advanced Plan\",\n",
    "    from_day=1,\n",
    "    from_month=2,\n",
    "    from_year=2020,\n",
    "    to_day=1,\n",
    "    to_month=2,\n",
    "    to_year=2020,\n",
    "    market_types_collection=[\"WIN\"],\n",
    "    countries_collection=[\"GB\"],\n",
    "    file_type_collection=[\"M\"]\\\n",
    "    ,\n",
    ")\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To downoad a file, `download_file()` is used, where we specify the download location (on Betfair) in `file_path` and the directory to which it is saved in `store_directory`. The filename is kept as is from Betfair. We both download the file and use the command to assign the file's location to the variable `download` so we can use it in subsequent operations. `file_path` below is a list input over which we iterate `.download_file()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130661.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096552.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136214.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133543.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130666.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096559.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136219.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130671.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133548.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096566.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136224.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133553.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130676.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168130245.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136229.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133558.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130681.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096580.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136234.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130686.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133563.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096587.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136239.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133568.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678694/1.168130691.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29677422/1.168096594.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678828/1.168136244.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/2/29678760/1.168133573.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133491.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133496.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133501.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133506.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133511.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133516.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133521.bz2', '/xds_nfs/edp_processed/ADVANCED/2020/Feb/1/29678749/1.168133526.bz2']\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130661.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096552.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136214.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133543.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130666.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096559.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136219.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130671.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133548.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096566.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136224.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133553.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130676.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130245.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136229.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133558.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130681.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096580.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136234.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130686.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133563.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096587.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136239.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133568.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130691.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096594.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136244.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133573.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133491.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133496.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133501.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133506.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133511.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133516.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133521.bz2\n",
      "/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133526.bz2\n"
     ]
    }
   ],
   "source": [
    "data_dir = project_dir / 'data' / 'raw' / 'api'\n",
    "\n",
    "available_files = file_list\n",
    "\n",
    "print(available_files)\n",
    "\n",
    "downloaded_files = [] #list of directories of each download\n",
    "\n",
    "for file in available_files:\n",
    "    download = trading.historic.download_file(file_path = file, store_directory = data_dir)\n",
    "    print(download)\n",
    "    downloaded_files.append(download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded file is .json formatted compressed in a bzip2 (.bz2) folder. The following extracts the file where it is downloaded. It is given no file extension, however it remains in .txt format and is readable in any text reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130661.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096552.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136214.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133543.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130666.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096559.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136219.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130671.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133548.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096566.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136224.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133553.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130676.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130245.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136229.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133558.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130681.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096580.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136234.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130686.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133563.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096587.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136239.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133568.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168130691.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168096594.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168136244.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133573.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133491.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133496.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133501.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133506.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133511.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133516.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133521.', '/Users/tombardrick/Documents/projects/betfair/betfair_project/data/raw/api/1.168133526.']\n"
     ]
    }
   ],
   "source": [
    "extracted_files = []\n",
    "\n",
    "for file in downloaded_files:\n",
    "    zipfile = BZ2File(file) # open the file\n",
    "    data = zipfile.read() # get the decompressed data\n",
    "    newfilepath = file.split('bz2')[0] # removing the extension and saving without a filetype\n",
    "    open(newfilepath, 'wb').write(data) # write an uncompressed file\n",
    "    extracted_files.append(newfilepath)\n",
    "    zipfile.close()\n",
    "    \n",
    "print(extracted_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using stream listener to read extracted data\n",
    "\n",
    "We now have a readable raw text file in Betfair's dictionary format. To interpret the data with python, betfairlightweight includes a stream listener which will interpret the input of historical data in the same way that it does for live data. The below is edited from [here](https://github.com/liampauling/betfair/blob/104ff4cb8734038cb9351e74d16dc7bd018111bc/examples/examplestreaminghistorical.py). \n",
    "\n",
    "This finds the chosen variables in the data file and outputs them in a .csv format in output.txt. Note: output.txt is ignored by git and is not uploaded into the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from betfairlightweight import StreamListener\n",
    "from betfairlightweight.streaming.stream import MarketStream\n",
    "\n",
    "class HistoricalStream(MarketStream):\n",
    "    # create custom listener and stream\n",
    "\n",
    "    def __init__(self, listener):\n",
    "        super(HistoricalStream, self).__init__(listener)\n",
    "\n",
    "    def on_process(self, market_books):\n",
    "        with open(\"output.txt\", \"a\") as output:\n",
    "            for market_book in market_books:\n",
    "                for runner in market_book.runners:\n",
    "\n",
    "                    # how to get runner details from the market definition\n",
    "                    market_def = market_book.market_definition\n",
    "                    runners_dict = {\n",
    "                        (runner.selection_id, runner.handicap): runner\n",
    "                        for runner in market_def.runners\n",
    "                    }\n",
    "                    runner_def = runners_dict.get(\n",
    "                        (runner.selection_id, runner.handicap)\n",
    "                    )\n",
    "\n",
    "                    output.write(\n",
    "                        \"%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n\"\n",
    "                        % (\n",
    "                            market_book.publish_time, #datetime.datetime\n",
    "                            market_book.market_id, #float\n",
    "                            market_book.status, #unicode\n",
    "                            market_book.inplay, #bool\n",
    "                            runner.selection_id, #int\n",
    "                            runner.last_price_traded or \"\", #float\n",
    "                            runner.total_matched or \"\", #float\n",
    "                            runner.sp.actual_sp or \"\", #float\n",
    "                            runner.adjustment_factor or \"\", #float\n",
    "                            runner.handicap or \"\", #float\n",
    "                            market_book.number_of_active_runners or \"\", #int\n",
    "                            runner.status,\n",
    "                            market_book.total_matched or \"\", #float\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "\n",
    "class HistoricalListener(StreamListener):\n",
    "    def _add_stream(self, unique_id, stream_type):\n",
    "        if stream_type == \"marketSubscription\":\n",
    "            return HistoricalStream(self)\n",
    "        \n",
    "listener = HistoricalListener(max_latency=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating the Historical Listener through the list of `extracted_files`. For the full day of racing 01/02/20, `output.txt` is 493mb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\") as output:\n",
    "    output.write(\"Time,MarketId,Status,Inplay,SelectionId,LastPriceTraded,TotalMatched,Sp,\\\n",
    "    AdjFactor,Handicap,NumRunnersActive,RunnerStatus,MktTotalMatched\\n\")\n",
    "    pass\n",
    "\n",
    "for file in extracted_files:\n",
    "    stream = trading.streaming.create_historical_stream(\n",
    "        directory=file,\n",
    "        listener=listener,\n",
    "    )\n",
    "    stream.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all downloaded files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in downloaded_files:\n",
    "    file = Path(file)\n",
    "    file.unlink()\n",
    "    \n",
    "for file in extracted_files:\n",
    "    file = Path(file)\n",
    "    file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read output.txt with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() #descriptive statistics for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating variables for better analysis\n",
    "\n",
    "To understand the evolution of matches at each price, we can create `TradeSize` by looking at the change in `TotalMatched` grouped by `LastPriceTraded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TradeSize'] = df.groupby(['MarketId','SelectionId', 'LastPriceTraded'])['TotalMatched'].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make race timeseries data comparable between events, we need an indicator of what stage the market is in. For example, betting behaviour is very different when the market is first created compared to in the 5 minutes before the off, or compared to in play. A logical anchoring point is the moment in which the race starts, at which point BSP is also defined.\n",
    "\n",
    "`TimeIndex` is created with time-zero defined at the second where `Inplay == True` for the first time for each `MarketId`, counting positively and negatively in either direction **in seconds**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['InplayBool'] = (df['Inplay'] == True) * 1\n",
    "# df['InplayBool'] = df['InplayBool'].diff()\n",
    "\n",
    "# race_start = df.iloc[df.index[df['InplayBool'] == 1.0].tolist(), 0].tolist()\n",
    "# race_start_index = df.index[df['InplayBool'] == 1.0].tolist()\n",
    "# market_ids = df['MarketId'].unique().tolist()\n",
    "\n",
    "# del df['InplayBool']\n",
    "\n",
    "# print(race_start)\n",
    "# print(race_start_index)\n",
    "# print(market_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# df2 = df.iloc[0:0]\n",
    "# df2['TimeIndex'] = None\n",
    "\n",
    "# for market, t_0 in zip(market_ids, race_start):\n",
    "#     df_temp = df[df['MarketId'] == market].reset_index()\n",
    "#     df_temp['TimeIndex'] = df_temp['Time'].apply(lambda x: (datetime.datetime.strptime(x[:19], \"%Y-%m-%d %H:%M:%S\") - datetime.datetime.strptime(t_0[:19], \"%Y-%m-%d %H:%M:%S\")))\n",
    "#     df2 = pd.concat([df2, df_temp])\n",
    "\n",
    "# df2['TimeIndex'] = df2['TimeIndex'].apply(lambda x: int(pd.Timedelta.total_seconds(x)))\n",
    "\n",
    "# del df2['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df2 # free up memory for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# copying df\n",
    "df_test = df.copy()\n",
    "\n",
    "# converting to datetime\n",
    "df_test['Time'] = pd.to_datetime(df['Time'], format=\"%Y-%m-%d %H:%M:%S\", errors='coerce')\n",
    "\n",
    "# calculating difference for each time point and inplay start\n",
    "df_test.assign(time_dif = df_test.groupby(level=0).apply(lambda x: x - x.loc[x['Inplay'] == True]['Time'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should definitely refine / remove needless time points before applying function\n",
    "# time taken seems to be exponentially longer by row otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# milliseconds important?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
