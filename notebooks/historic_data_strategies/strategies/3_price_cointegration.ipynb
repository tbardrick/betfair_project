{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy Idea 2 : \"Cointegration - pairs trading - version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes (to do)\n",
    "* Think about whether using the hedge profit formula a minimum deviated price can be found, from which if the spread returns to the mean, it will be a profitable bet\n",
    "* See if there are pairs which deviate away from and back to a mean spread, but the return to the spread isn't a convergence of prices and is instead a move of one horse or both horses in the same direction to different extents.\n",
    "* To account for the above, edit the bet function so that it identifies the short and long positions by the horses deviation from its mean rather than by using the spread's deviation from its mean.\n",
    "* Make another pc profit hedge column where the final price is the deviation from the mean spread multiplied by the weight of each horse\n",
    "\n",
    "Long term:\n",
    "* Use predictive method to decide when to bet\n",
    "\n",
    "Observations that may be useful:\n",
    "* The mean spread between two horses is the same as the spread of the mean prices of each horse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0 : Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "from pathlib import Path, PurePath \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payout(bp, bs, lp, ls, c = 0):\n",
    "    if ls == '?':\n",
    "        ls = lay_hedge_stake(bp, bs, lp, c)\n",
    "        payoff = (bp - 1) * bs * (1 - c) - (lp - 1) * ls\n",
    "        return payoff, ls\n",
    "    elif bs == '?':\n",
    "        bs = bet_hedge_stake(lp, ls, bp, c)\n",
    "        payoff = (bp - 1) * bs * (1 - c) - (lp - 1) * ls\n",
    "        return payoff, bs \n",
    "\n",
    "def lay_hedge_stake(bp, bs, lp, c):\n",
    "    return (((bp - 1) * bs * (1 - c)) + bs) / (lp)\n",
    "\n",
    "def bet_hedge_stake(lp, ls, bp, c):\n",
    "    return ls * (lp - c) / (bp * (1 - c) + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12906, 307)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SelectionId</th>\n",
       "      <th>MarketId</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Distance</th>\n",
       "      <th>RaceType</th>\n",
       "      <th>BSP</th>\n",
       "      <th>NoRunners</th>\n",
       "      <th>BS:T-60</th>\n",
       "      <th>BS:T-59</th>\n",
       "      <th>BS:T-58</th>\n",
       "      <th>...</th>\n",
       "      <th>LS:T+5</th>\n",
       "      <th>LS:T+6</th>\n",
       "      <th>LS:T+7</th>\n",
       "      <th>LS:T+8</th>\n",
       "      <th>LS:T+9</th>\n",
       "      <th>LS:T+10</th>\n",
       "      <th>LS:T+11</th>\n",
       "      <th>LS:T+12</th>\n",
       "      <th>LS:T+13</th>\n",
       "      <th>LS:T+14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11688029.0</td>\n",
       "      <td>1.166898</td>\n",
       "      <td>Southwell</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>9.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.86</td>\n",
       "      <td>...</td>\n",
       "      <td>4.76</td>\n",
       "      <td>7.70</td>\n",
       "      <td>3.07</td>\n",
       "      <td>41.07</td>\n",
       "      <td>8.05</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.05</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13331255.0</td>\n",
       "      <td>1.166898</td>\n",
       "      <td>Southwell</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.50</td>\n",
       "      <td>64.89</td>\n",
       "      <td>38.54</td>\n",
       "      <td>...</td>\n",
       "      <td>16.44</td>\n",
       "      <td>7.38</td>\n",
       "      <td>18.12</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.09</td>\n",
       "      <td>15.50</td>\n",
       "      <td>3.82</td>\n",
       "      <td>66.43</td>\n",
       "      <td>192.93</td>\n",
       "      <td>136.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SelectionId  MarketId      Venue  Distance RaceType  BSP  NoRunners  \\\n",
       "0   11688029.0  1.166898  Southwell       8.0     Flat  9.2        7.0   \n",
       "1   13331255.0  1.166898  Southwell       8.0     Flat  4.3        7.0   \n",
       "\n",
       "   BS:T-60  BS:T-59  BS:T-58  ...  LS:T+5  LS:T+6  LS:T+7  LS:T+8  LS:T+9  \\\n",
       "0     4.15     5.98     6.86  ...    4.76    7.70    3.07   41.07    8.05   \n",
       "1    41.50    64.89    38.54  ...   16.44    7.38   18.12    5.44    4.09   \n",
       "\n",
       "   LS:T+10  LS:T+11  LS:T+12  LS:T+13  LS:T+14  \n",
       "0     3.74     1.85     7.05     3.89     0.41  \n",
       "1    15.50     3.82    66.43   192.93   136.06  \n",
       "\n",
       "[2 rows x 307 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in data\n",
    "project_dir = Path.cwd().parents[2]\n",
    "data_dir = project_dir / 'data' / 'processed' / 'api' / 'advanced' / 'adv_data.csv'\n",
    "df = pd.read_csv(data_dir, header = 1, low_memory = False, index_col = 0)\n",
    "print(df.shape)\n",
    "\n",
    "# defining variables\n",
    "back_prices = [col for col in df.columns if 'BP' in col]\n",
    "back_sizes = [col for col in df.columns if 'BS' in col]\n",
    "lay_prices = [col for col in df.columns if 'LP' in col]\n",
    "lay_sizes = [col for col in df.columns if 'LS' in col]\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach to pairs trading\n",
    "\n",
    "__2.0__ **- [Herlemont (2004)](http://docs.finance.free.fr/DOCS/Yats/cointegration-en%5B1%5D.pdf) paper**\n",
    "\n",
    "Herlemont describes in detail the econometrics of pairs trading for financial market assets. The following partly follows his commentary with some additional clarifications and discussion relating to horse racing.\n",
    "\n",
    "**2.1 - Testing for mean reversion**\n",
    "\n",
    "The aim is to identify odds that move together and whose spread is mean reverting. For the purposes of horse racing pairs, mean reversion is essential. Our objective is to capture prices whose spread has (temporarily) deviated from its mean. If this can be found, bets can be made to take advantage of the possible reversion.\n",
    "\n",
    "A stochastic process $y_{t}$ that is weakly stationary has the following properties for all $t$:\n",
    "\n",
    "* $E[y_{t}] = \\mu < \\infty$\n",
    "* $var(y_{t}) = \\gamma_{0} < \\infty$\n",
    "* $cov(y_{t}, y_{t-j}) = \\gamma_{j} < \\infty, j = 1, 2, 3 ...$\n",
    "\n",
    "(constant mean, constant variance, covariance between two observations depends only on the distance in time between them)\n",
    "\n",
    "A weakly stationary $I(0)$ series:\n",
    "* Fluctuates around its mean with a finite variance that does not depend upon time.\n",
    "* Is mean-reverting: it has tendency to return to its mean.\n",
    "* Has limited memory; the effect of a shock dies out. Autocorrelations die out (fairly) rapidly.\n",
    "\n",
    "With two horse's odds, $A_{t}$ and $B_{t}$, we look at $y_{t} = \\log \\frac{A_{t}}{B_{t}} = \\log A_{t} - \\log B_{t}$. This is once again the spread between the prices of the two horses, defined slightly differently. We want to find a pair which has a weakly stationary spread. We are interested in the ($AR(1)$) process \n",
    "\n",
    "$y_{t} = c + \\theta y_{t-1} + \\varepsilon_{t}$,\n",
    "\n",
    "or the log odds ratio over time. If this is weakly stationary, it would suggest a mean reverting process. \n",
    "\n",
    "The three previous conditions, and a stability condition that $|\\theta|<1$ (that the process $y_{t}$ is not a random walk or that it follows an eratic positive-to-negative pattern) must hold.\n",
    "______\n",
    "\n",
    "A Dickey-Fuller stationarity test can be carried out on the log ratio of the prices to test whether a process is weakly stationary. If we carry out the regression:\n",
    "\n",
    "$\\Delta y_{t} = \\mu + \\omega y_{t-1} + \\varepsilon_{t}$\n",
    "\n",
    "where the null hypothesis that $\\omega = 0$ is that the 'true' relationship is $\\Delta y_{t} = \\mu + \\varepsilon_{t} \\Leftrightarrow y_{t} = \\mu + y_{t-1} + \\varepsilon_{t}$, or a random walk with starting point $y_{0} = \\mu$.\n",
    "\n",
    "If we can reject the null hypothesis, the price ratio is weakly stationary and thereby mean-reverting.\n",
    "\n",
    "A Dickey-Fuller test is required for each possible pair of horses in a race, or $\\frac{n(n-1)}{2}$ regressions, where $n$ is the number of horses.\n",
    "\n",
    "While we are interested in the stochastic process $y_{t}$, we do not need to carry out the regression of $y_{t} = c + \\theta y_{t-1} + \\varepsilon_{t}$ for the purpose of finding pairs. This relationship between a pair of odds itself is not important to quantify. We are only interested in the features of the process. \n",
    "____\n",
    "\n",
    "*In the previous analysis, the test for whether two odds formed a pair was to find the pair with the smallest sum of absolute differences over time in the standardised prices. That method would allow maximum 1 pair to be found per race, and the validity of that pair would not be confirmed statisticallyather. Rather, the pair's feasibilty for a trade would be tested for afterwards based on profitability. I have more confidence in the approach in this section.*\n",
    "\n",
    "**2.2 - Screening pairs**\n",
    "\n",
    "Herlemont describes rules to ensure that market neutrality is more achievable in pairs trading. The idea is to pick stocks with very similar characteristics like same industry and similar market betas, with the intention of minimising asymmetric shocks to the price of one stock and not the other. For example in the case of two stocks, the share on which you are long is a business heavily dependent on oil, while the other share is not, a surge in oil prices which dampens profitability of your long share will likely see its price fall, ruining the pairs trade. In the case of shares, the simplest solution would be to pick shares in similar industries with similar market betas (or with similar idiosyncratic risks).\n",
    "\n",
    "For horses, the external factors influencing prices (news about runners, changing weather conditions, etc.) will usually always have asymmetric effects. This may be avoidable through picking horses with similar fundamental characteristics. However, this is very complicated. My hope is that the pair finding mechanism picks horses where this is already the case, because the market reacts the same way to news for these horse pairs.\n",
    "\n",
    "We cannot follow a beta-based approach because there are not 'market-wide fluctuations' of the same sort. However, there is the fact that the implied probability of all horses in the market book is equal to approximately 1. Therefore, you could say that for a given change in implied probability for one horse, the sum of the changes in the odds of all the remaining horses is the negative the change for the given horse:\n",
    "\n",
    "$\\Delta O_{i} = - \\sum_{j = 1, j \\neq i}^{N_{h}} \\Delta O_{j} $\n",
    "\n",
    "There is therefore interdependence between all prices across the market. It's possible that this will cause an endogeneity problem in regressions between separate horses, as the changes in the dependent variable necessarily impact the explanatory variable. However, the impact is likely to be very small, and will be smaller the greater the number of horses. \n",
    "\n",
    "*In Bebbington's analysis, he describes that betting £1 on one of the horses and £$\\beta$ on the other creates a market neutral bet. This is incorrect, and it appears that he has misunderstood hedging in this context. In that analysis, $\\beta = \\frac{y_{t}}{x_{t}}$, and therefore he is simply considering the ratio of the prices of the horses, the same ratio considered when determining the optimal stake for two given prices in a hedge. It is correct that on a single horse this creates a market neutral bet, however neutrality in horse racing means neutral to the outcome of the race. Any bet neutral to the race outcome is definitively neutral to the market. When betting on separate horses, the bets on each horse must be made neutral separately. Additionally, the use of $\\beta$ in staking is unneccesary. Consider the case where £$BS$ has been bet on horse A at price $BP$. Now, horse A is priced at $LP$. The optimal stake to bet on LP is £$LS = \\frac{BS * BP}{LP}$. In the aforementioned regression, $BS = 1$, hence $\\beta = \\frac{y_{t} * 1}{x_{t}}$ is the optimal stake only for bets of £1, otherwise it would be $S*\\beta$. More importantly, using the estimated $\\beta$ to find the an approximation of the optimal stake makes no sense when you can simply find the optimal stake with the aforementioned equation.*\n",
    "\n",
    "**2.3 - Trading rules**\n",
    "\n",
    "Timing rules must be added. \n",
    "\n",
    "Herlemont's basic rule is \"to open a position when the ratio of two share prices hits the 2 rolling standard deviation [difference from the 130-day rolling mean] and close it when the ratio returns to the mean.\"\n",
    "\n",
    "To avoid opening a position on stocks that are deviating from the mean and are going to deviate further, Herlemont describes that \"the position is not opened when the ratio breaks the two-standard-deviations limit for the first time, but rather when it crosses it to revert to the mean again.\"\n",
    "\n",
    "This can be achieved with the horse odds, of course in far smaller time scales. The current dataset is in 5-minute intervals for the three hours before a race; this should likely be expanded.\n",
    "\n",
    "Stop losses should be included and trade length should also be limited.\n",
    "\n",
    "Rules:\n",
    "1. Trade on pairs whose spread is reapproaching the mean from a deviated position\n",
    "2. Stop loss at x% of the initial position\n",
    "3. Don't hold open pairs trades for longer than x hours. \n",
    "\n",
    "It should be possible to quantify the average length of time required for a mean reversion and therefore the maximum logical time to hold open a position by looking at past data.\n",
    "\n",
    "**2.4 - Other tests and considerations**\n",
    "\n",
    "1. It should be ensured that the regression results of one price on another are not spurious (as with the regression in 2.5). $\\beta$ could be statistically meaningless if it is, meaning that it makes no sense to use it.\n",
    "2. I will also test whether $y_{t} = c + \\theta y_{t-1} + \\varepsilon_{t}$ is $I(1)$, or difference stationary. If we can rule this out, this gives more confidence in the 'weak-stationarity' of the spread over time.\n",
    "3. I will look out for $\\omega$ in the DF test that are close to 1 yet pass the DF test. They will have lots of features of a random walk, so the pairs exercise might be meaningless.\n",
    "4. Structural breaks (in this case, large instantaneous jumps in the spread) may make series that are stationary on either side of the break appear non-stationary. This is hard to account for in testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Sample Function\n",
    "\n",
    "def sample_dataframe():\n",
    "    sample_df = df[df['MarketId'] == df['MarketId'].sample(1).item()]\n",
    "    sample_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    bp_df = sample_df[['SelectionId'] + back_prices].copy()\n",
    "    new_cols = bp_df.columns.str.replace(\"[BP:T]\", \"\").str.replace(\"[+]\", \"\")\n",
    "    bp_df.rename(columns = dict(zip(bp_df.columns, new_cols)), inplace = True)\n",
    "    bp_t_df = bp_df.T.copy()\n",
    "    bp_t_df.columns = [\"h\" + str(int(column)) for column in bp_t_df.iloc[0]]\n",
    "    bp_t_df = bp_t_df.iloc[1:-15] # using the 60 pre-off price data points\n",
    "    bp_t_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    lp_df = sample_df[['SelectionId'] + lay_prices].copy()\n",
    "    new_cols = lp_df.columns.str.replace(\"[LP:T]\", \"\").str.replace(\"[+]\", \"\")\n",
    "    lp_df.rename(columns = dict(zip(lp_df.columns, new_cols)), inplace = True)\n",
    "    lp_t_df = lp_df.T.copy()\n",
    "    lp_t_df.columns = [\"h\" + str(int(column)) for column in lp_t_df.iloc[0]] #rename columns to horse ids\n",
    "    lp_t_df = lp_t_df.iloc[1:-15] #remove horse ids, remove inplay data\n",
    "    lp_t_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #taking mid point df\n",
    "    mid_df = bp_t_df.add(lp_t_df, fill_value=0) / 2\n",
    "    \n",
    "    #using log price data <-- This is where the decision to take only the first 30 time periods for analysis is made\n",
    "    log_mid = np.log(mid_df[:30]).copy()\n",
    "    \n",
    "    return bp_t_df, lp_t_df, mid_df, log_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Dickey Fuller setup and test; will work for any dataframe where the horses to pair up each have their own column and the heading is some horse identifier\n",
    "\n",
    "def dickey_fuller_test(log_horse_prices): #log prices are required since stationarity relates to relative movements of two horses, not absolute movements\n",
    "    \n",
    "    # Create a dataframe where each column is log(horse a's prices) - log(horse b's prices). one new column for all n(n-1)/2 possible pairs\n",
    "    combos = list(itertools.combinations(log_horse_prices.columns, 2))\n",
    "\n",
    "    # Create a dataframe for the Dickey Fuller test where the data in each column is log(A/B), the prices of each horse in the possible pair\n",
    "    for pair in combos:\n",
    "        if pair == combos[0]:\n",
    "            new_series = log_horse_prices[pair[0]] - log_horse_prices[pair[1]]\n",
    "            dickey_fuller_df = pd.DataFrame(new_series)\n",
    "        else:\n",
    "            new_series = log_horse_prices[pair[0]] - log_horse_prices[pair[1]]\n",
    "            dickey_fuller_df = pd.concat([dickey_fuller_df, new_series], axis=1)\n",
    "\n",
    "    dickey_fuller_df.columns = [pair[0] + \"_\" + pair[1] for pair in combos] \n",
    "    dickey_fuller_df['const'] = 1\n",
    "\n",
    "    # Performing the Dickey Fuller test on each column and returning the results in dickey_fuller_results_df. The results df gives the pair identifier and their test critical value\n",
    "    dickey_fuller_results = {'pair' : [], 'coef' : [], 'critical_value' : []}\n",
    "\n",
    "    for column in dickey_fuller_df:\n",
    "        if column == 'const':\n",
    "            continue\n",
    "        reg = sm.OLS(endog = dickey_fuller_df[column].diff(), exog = dickey_fuller_df[['const', column]].shift(1), missing = 'drop')\n",
    "        results = reg.fit()\n",
    "        dickey_fuller_results['pair'].append(column)\n",
    "        dickey_fuller_results['coef'].append(results.params[1])\n",
    "        dickey_fuller_results['critical_value'].append(results.tvalues[1])\n",
    "\n",
    "    dickey_fuller_results_df = pd.DataFrame(dickey_fuller_results)\n",
    "    \n",
    "    return dickey_fuller_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the viable pairs from the Dickey Fuller test results table. Main objective to define 'pairs_df'\n",
    "\n",
    "def race_pairs(results_df, significance_level = 0.01):\n",
    "\n",
    "    if significance_level == 0.01: #note - this is for a T-dimension of 50. The greater T the lower the CV\n",
    "        critical_value = - 3.58\n",
    "        \n",
    "    elif significance_level == 0.05:\n",
    "        critical_value = - 2.93\n",
    "        \n",
    "    else: print(\"Please input signfiance level as 0.01 or 0.05\")\n",
    "        \n",
    "    if results_df['critical_value'].min() < critical_value:\n",
    "        pairs_df = results_df.loc[results_df['critical_value'] < critical_value].copy() #all possible pairs\n",
    "        return pairs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Betting function determines based on the spread and deviation which sides to back and lay\n",
    "\n",
    "# def bet(idx_open, time_open):\n",
    "#     if (pair_df['spread'].iloc[open_trade_idx] > pair_spread_mean) and (pair_spread_mean > 0) or (pair_df['spread'].iloc[open_trade_idx] > pair_spread_mean) and (pair_spread_mean < 0):\n",
    "#         #back to lay A (short)\n",
    "#         bp_a = pair_df[horse_a + \"_bp\"].iloc[idx_open]\n",
    "#         lp_a = pair_df[horse_a + \"_lp\"].iloc[idx_open + time_open]\n",
    "\n",
    "#         win_side_a, loss_side_a = payout(bp_a, 1, lp_a, '?')\n",
    "\n",
    "#         #lay to back X (long)\n",
    "#         lp_b = pair_df[horse_b + \"_lp\"].iloc[idx_open]\n",
    "#         bp_b = pair_df[horse_b + \"_bp\"].iloc[idx_open + time_open]\n",
    "\n",
    "#         win_side_b, loss_side_b = payout(bp_b, '?', lp_b, 1)\n",
    "\n",
    "#         return win_side_a, win_side_b\n",
    "\n",
    "#     elif (pair_df['spread'].iloc[open_trade_idx] < pair_spread_mean) and (pair_spread_mean < 0) or (pair_df['spread'].iloc[open_trade_idx] < pair_spread_mean) and (pair_spread_mean > 0): \n",
    "#         #lay to back A (long)\n",
    "#         lp_a = pair_df[horse_a + \"_lp\"].iloc[idx_open]\n",
    "#         bp_a = pair_df[horse_a + \"_bp\"].iloc[idx_open + time_open]\n",
    "\n",
    "#         win_side_a, loss_side_a = payout(bp_a, '?', lp_a, 1)\n",
    "\n",
    "#         #back to lay A (short)\n",
    "#         bp_b = pair_df[horse_b + \"_bp\"].iloc[idx_open]\n",
    "#         lp_b = pair_df[horse_b + \"_lp\"].iloc[idx_open + time_open]\n",
    "\n",
    "#         win_side_b, loss_side_b = payout(bp_b, 1, lp_b, '?')\n",
    "\n",
    "#         return win_side_a, win_side_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betting function determines based on the spread and deviation which sides to back and lay\n",
    "# This function is used as a filter for betting\n",
    "\n",
    "def bet_prof_pc(bp_a, lp_a, bp_b, lp_b, spread, weight_a, weight_b):\n",
    "    \n",
    "    #weighted stakes\n",
    "    stake_a_o = weight_a * stake\n",
    "    stake_b_o = weight_b * stake     \n",
    "    \n",
    "    if (spread > pair_spread_mean) and (pair_spread_mean > 0) or (spread > pair_spread_mean) and (pair_spread_mean < 0):\n",
    "        #back to lay A (short)\n",
    "        payoff_a, stake_a_c = payout(bp_a, stake_a_o, horse_a_mean_lp, '?')\n",
    "\n",
    "        #lay to back X (long)\n",
    "        payoff_b, stake_b_c = payout(bp_b, '?', horse_b_mean_bp, stake_b_o)\n",
    "\n",
    "        prof_pc = 100 * (payoff_a + payoff_b) / (stake_a_o + stake_b_o + stake_a_c + stake_b_c)\n",
    "        return prof_pc\n",
    "\n",
    "    elif (spread < pair_spread_mean) and (pair_spread_mean < 0) or (spread < pair_spread_mean) and (pair_spread_mean > 0): \n",
    "        #lay to back A (long)\n",
    "        payoff_a, stake_a_c = payout(horse_a_mean_bp, '?', lp_a, stake_a_o)\n",
    "\n",
    "        #back to lay A (short)\n",
    "        payoff_b, stake_b_c = payout(bp_b, stake_b_o, horse_b_mean_lp, '?')\n",
    "\n",
    "        prof_pc = 100 * (payoff_a + payoff_b) / (stake_a_o + stake_b_o + stake_a_c + stake_b_c)\n",
    "        return prof_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betting function determines based on the spread and deviation which sides to back and lay\n",
    "# This function is used as a filter for betting\n",
    "\n",
    "def bet_prof_pc_2(bp_a, lp_a, bp_b, lp_b, spread, spread_mean, weight_a = 1, weight_b = 1):\n",
    "    \n",
    "    #weighted stakes\n",
    "    stake_a_o = weight_a * stake\n",
    "    stake_b_o = weight_b * stake  \n",
    "    \n",
    "    #anticipated close prices    \n",
    "    a_plus_b = ((bp_a + lp_a) / 2 ) + ((bp_b + lp_b) / 2 ) #since the spreads are based on midpoints, so should a+b\n",
    "    if spread_mean > 0:\n",
    "        x = (spread_mean - spread) / a_plus_b\n",
    "    else: \n",
    "        x = (- spread_mean - spread) / a_plus_b\n",
    "\n",
    "    if (spread > spread_mean) and (spread_mean > 0) or (spread > spread_mean) and (spread_mean < 0):\n",
    "        #back to lay A (short)\n",
    "        lp_close = lp_a * (1 + x)\n",
    "        payoff_a, stake_a_c = payout(bp_a, stake_a_o, lp_close, '?')\n",
    "\n",
    "        #lay to back X (long)\n",
    "        bp_close = bp_b * (1 - x)\n",
    "        payoff_b, stake_b_c = payout(bp_b, '?', bp_close, stake_b_o)\n",
    "\n",
    "        prof_pc = 100 * (payoff_a + payoff_b) / (stake_a_o + stake_b_o + stake_a_c + stake_b_c)\n",
    "        return prof_pc\n",
    "\n",
    "    elif (spread < spread_mean) and (spread_mean < 0) or (spread < spread_mean) and (spread_mean > 0): \n",
    "        #lay to back A (long)\n",
    "        bp_close = bp_b * (1 - x)\n",
    "        payoff_a, stake_a_c = payout(bp_close, '?', lp_a, stake_a_o)\n",
    "\n",
    "        #back to lay A (short)\n",
    "        lp_close = lp_a * (1 + x)\n",
    "        payoff_b, stake_b_c = payout(bp_b, stake_b_o, lp_close, '?')\n",
    "\n",
    "        prof_pc = 100 * (payoff_a + payoff_b) / (stake_a_o + stake_b_o + stake_a_c + stake_b_c)\n",
    "        return prof_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betting function determines based on the spread and deviation which sides to back and lay\n",
    "# This function is used for pairs trade payoffs\n",
    "\n",
    "def bet(open_idx, close_idx, stake_a, stake_b):\n",
    "    if (pair_df['spread'].iloc[open_idx] > pair_spread_mean) and (pair_spread_mean > 0) or (pair_df['spread'].iloc[open_idx] > pair_spread_mean) and (pair_spread_mean < 0):\n",
    "        #back to lay A (short)\n",
    "        bp_a = pair_df[horse_a + \"_bp\"].iloc[open_idx]\n",
    "        lp_a = pair_df[horse_a + \"_lp\"].iloc[close_idx]\n",
    "\n",
    "        payoff_a, stake_a_c = payout(bp_a, stake_a, lp_a, '?')\n",
    "\n",
    "        #lay to back X (long)\n",
    "        lp_b = pair_df[horse_b + \"_lp\"].iloc[open_idx]\n",
    "        bp_b = pair_df[horse_b + \"_bp\"].iloc[close_idx]\n",
    "\n",
    "        payoff_b, stake_b_c = payout(bp_b, '?', lp_b, stake_b)\n",
    "\n",
    "        return payoff_a, payoff_b, stake_a_c, stake_b_c\n",
    "\n",
    "    elif (pair_df['spread'].iloc[open_idx] < pair_spread_mean) and (pair_spread_mean < 0) or (pair_df['spread'].iloc[open_idx] < pair_spread_mean) and (pair_spread_mean > 0): \n",
    "        #lay to back A (long)\n",
    "        lp_a = pair_df[horse_a + \"_lp\"].iloc[open_idx]\n",
    "        bp_a = pair_df[horse_a + \"_bp\"].iloc[close_idx]\n",
    "\n",
    "        payoff_a, stake_a_c = payout(bp_a, '?', lp_a, stake_a)\n",
    "\n",
    "        #back to lay A (short)\n",
    "        bp_b = pair_df[horse_b + \"_bp\"].iloc[open_idx]\n",
    "        lp_b = pair_df[horse_b + \"_lp\"].iloc[close_idx]\n",
    "\n",
    "        payoff_b, stake_b_c = payout(bp_b, stake_b, lp_b, '?')\n",
    "\n",
    "        return payoff_a, payoff_b, stake_a_c, stake_b_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading rules\n",
    "\n",
    "**Strategy 1**\n",
    "\n",
    "The original strategy I had attempted to implement mostly followed the previous discussion, opening a trade when a pair's current spread is over 1 standard deviation from the mean, and then closing out once it returns to the mean, or closing the position if the deviation becomes too large (3 or 3.5 standard deviations from the mean) and it seems like the process will not revert to the mean spread. The code also rules out pairs where in the given series the deviations are too large. This of course couldn't be implemented in practise, but it could probably be proxied with the variance or something like that. In this basic form this was loss making.\n",
    "\n",
    "**Strategy 2**\n",
    "\n",
    "Based on the idea of mean-reversion, this strategy creates a column which calculates the profit on a pairs trade where the opening prices are those of the given row and the closing prices are the mean prices of each horse. Thus, rather than looking at whether the spread reverts to the mean it looks at whether the horses revert to their means. A position would be opened if hedging to the mean gives a 1.5% profit or more, and closed when the same code identifies an approximately 0% profit. It also implemented a stop loss, exiting a position if either horse's price gets too far from its mean, identified by the profit to the mean being excessively large. As is, this strategy was loss making.\n",
    "\n",
    "**Strategy 3**\n",
    "\n",
    "Similar to Strategy 2, the idea is to calculate the profit in a pairs trade opening at each given set of prices at taking the closing price as the nearest prices that restore the spread to its mean, assuming that movement occurs in both horse's prices.\n",
    "\n",
    "Suppose that the prices of A and B are currently $a = 20$, $b = 10$, and the mean spread $\\overline{S} = 15$. Currently we have $a_{t} - b_{t} = S_{current}$ or $20 - 10 = 10$, and we want to have an estimate for possible future prices that have a spread of 15: $a_{t+i} - b_{t+i} = \\overline{S} = 15$. The shortest path to those prices is for both prices to move the same relative amount (%) in opposite directions. Since the spread is below the mean in this case, the larger price increases and the smaller price decreases.\n",
    "\n",
    "$a_{t}(1+x) - b_{t}(1-x)= \\overline{S} \\Rightarrow 20(1+x) + 10(1-x) = 15 \\Rightarrow x = \\frac{\\overline{S} + b_{t} - a_{t}}{a_{t}+b_{t}} = \\frac{15 + 10 - 20}{20+10} = \\frac{1}{6}$\n",
    "\n",
    "Therefore the closing price for A is assumed to be $20(1+\\frac{1}{6}) = 23.33$ and B $10(1-\\frac{1}{6}) = 8.33$. Then with the price of A expecting to increase we would lay then back, and with B back then lay. If the current prices were instead $a = 30$ and still $b = 10$, using the same equation $x = \\frac{15+10-30}{40} = -\\frac{5}{40} = -0.125$, giving expected prices $30(1-0.125) = 26.25$ and B $10(1--0.125) = 11.25$, and in this case you would back to lay A and lay to back B. Note: this equation must change $\\overline{S}$ to $-\\overline{S}$ when $b>a$, since in that case $a-b$, or the spread, is negative.\n",
    "\n",
    "For the purposes of the implementing this in a function $b_{t}-a_{t} = -(a_{t}-b_{t})$ in the numerator of the function is equivalent to $-spread_{t}$. \n",
    "\n",
    "This strategy is then implemented with bets starting where the expected profit is 2%, closing out if the margin is too large or exiting bets once the expected profit returns to 0.\n",
    "\n",
    "**Things still to be implemented into the strategies**\n",
    "\n",
    "* Making bets only when the prices begin to reapproach the mean, rather than only when the cross a threshold (which could mean that they are still moving away from the mean)\n",
    "\n",
    "### Monte Carlo simulation\n",
    "\n",
    "n repetitions of the above with profit summed over all trades.\n",
    "\n",
    "What is going on below? (Ignoring ## stats code and text printouts)\n",
    "\n",
    "1. The number of interations to simulate, n, is defined\n",
    "\n",
    "2. `sample_dataframe()` is used to grab a new random race\n",
    "    \n",
    "    Within this function, the lay prices, back prices, mid point prices and log prices (used in the Dickey Fuller [DF] tests) are defined\n",
    "    This would be the place to alter for manipulations made in the price data. For example, changing which log prices are used in the DF test.\n",
    "    \n",
    "3. `dickey_fuller_test()` is used to perform a DF test and create a dataframe with pair_identifers and test results. It would probably make sense to move the pair identifiers code from this function\n",
    "\n",
    "4. `race_pairs()` is used to filter the DF tests for only those where there looks to be cointegration at the 1% or 5% significance level\n",
    "\n",
    "5. Before the trading strategy code, the iteration is aborted if the race pairs dataframe is empty (no pairs in that race)\n",
    "\n",
    "The trading strategy code\n",
    "\n",
    "6. Firstly, races where more than 5 pairs are found are rejected. This is an abitrary rule based on the suspicion that some races erroneously look like far too many horses are pairs.  ** Considering changing this**\n",
    "\n",
    "7. Then in PAIR DATAFRAME SETUP, iterating through each identified pair in the given race, a dataframe of time series of each horse's prices and the pairs spread (in actual prices) is created.\n",
    "\n",
    "8. The in the TRADING STRATEGY SETUP part of the code time points at which a pairs trade should be opened or closed are identified.\n",
    "\n",
    "9. The BETS part of the code creates a weighted stake if needed and uses the `bet()` function to calculate the profit from opening and closing bets at those indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-59236c4ac387>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df.drop_duplicates(inplace=True)\n",
      "C:\\Users\\edwar\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05513261046849394\n",
      "-0.11656866634794749\n",
      "0.10863391454610172\n",
      "-0.19599051655524935\n",
      "0.1494205552907999\n",
      "-0.03291869732641439\n",
      "-0.032790390132908076\n",
      "100 of 1000 iterations completed.\n",
      "0.005914750624559595\n",
      "0.1724881484578913\n",
      "0.05812046280337624\n",
      "-0.12135385614836647\n",
      "0.2116565965942674\n",
      "-0.15631035494090129\n",
      "-0.16254277908797654\n",
      "0.05812046280337624\n",
      "0.11657268317025515\n",
      "0.038996823753363996\n",
      "0.017850418369820487\n",
      "0.04208094726607303\n",
      "200 of 1000 iterations completed.\n",
      "0.03434027729030609\n",
      "0.12776348134798354\n",
      "0.22999787051715626\n",
      "-0.06652270153862405\n",
      "0.2677879243153476\n",
      "0.10091667163893092\n",
      "0.1578627148384335\n",
      "-0.07100000156908648\n",
      "-0.26884399775799583\n",
      "-0.11227027318474347\n",
      "-0.056831172830334786\n",
      "300 of 1000 iterations completed.\n",
      "-0.06273722483813116\n",
      "0.04765990634530681\n",
      "-0.07040088600175887\n",
      "-0.041135765826429194\n",
      "0.18861332364143402\n",
      "0.040957622528316584\n",
      "-0.032790390132908076\n",
      "0.2045369159220789\n",
      "400 of 1000 iterations completed.\n",
      "0.014577998025699035\n",
      "0.11326075236393418\n",
      "0.1155764572172393\n",
      "-0.00892866357899158\n",
      "-0.004465933031752023\n",
      "-0.02987668112801689\n",
      "-0.05513261046849394\n",
      "0.11657268317025515\n",
      "0.2045369159220789\n",
      "0.014577998025699035\n",
      "0.11326075236393418\n",
      "0.031213689525290356\n",
      "-0.041135765826429194\n",
      "-0.15469410113415583\n",
      "500 of 1000 iterations completed.\n",
      "0.07872496812027041\n",
      "0.07466996457353359\n",
      "-0.07238179145832535\n",
      "-0.12135385614836647\n",
      "0.04208094726607303\n",
      "0.257097607666525\n",
      "0.16196855579439617\n",
      "-0.060513866540435335\n",
      "-0.08591547578326747\n",
      "0.05264589905355561\n",
      "0.026763156386890863\n",
      "-0.019289207590790225\n",
      "-0.207854842582063\n",
      "0.10091667163893092\n",
      "0.08620456137613175\n",
      "0.2045369159220789\n",
      "-0.032790390132908076\n",
      "-0.01634000650431311\n",
      "0.23145832235730524\n",
      "-0.19023701302134288\n",
      "600 of 1000 iterations completed.\n",
      "-0.2265112543628005\n",
      "0.005914750624559595\n",
      "0.1724881484578913\n",
      "0.07872496812027041\n",
      "-0.08308925147075374\n",
      "-0.07100000156908648\n",
      "0.061244157084924034\n",
      "700 of 1000 iterations completed.\n",
      "-0.005967008904885107\n",
      "0.10091667163893092\n",
      "-0.032790390132908076\n",
      "-0.15539835092672405\n",
      "0.07784596295811141\n",
      "0.07872496812027041\n",
      "-0.15539835092672405\n",
      "0.257097607666525\n",
      "0.16196855579439617\n",
      "0.10091667163893092\n",
      "800 of 1000 iterations completed.\n",
      "-0.00892866357899158\n",
      "-0.004465933031752023\n",
      "-0.02987668112801689\n",
      "-0.18236660539083482\n",
      "0.1602036635739783\n",
      "0.07466996457353359\n",
      "-0.07238179145832535\n",
      "0.21136587055704892\n",
      "0.21136587055704892\n",
      "0.013924263844928397\n",
      "0.09045125390365882\n",
      "0.12447135526248232\n",
      "-0.000551706660877116\n",
      "0.07784596295811141\n",
      "0.07466996457353359\n",
      "-0.07238179145832535\n",
      "0.1578627148384335\n",
      "900 of 1000 iterations completed.\n",
      "0.061244157084924034\n",
      "-0.032790390132908076\n",
      "0.09045125390365882\n",
      "0.12447135526248232\n",
      "-0.000551706660877116\n",
      "-0.23652109986565995\n",
      "-0.15723003553881743\n",
      "-0.2361464697631983\n",
      "-0.274303395343903\n",
      "-0.00892866357899158\n",
      "-0.004465933031752023\n",
      "-0.02987668112801689\n",
      "0.257097607666525\n",
      "0.16196855579439617\n",
      "0.1578627148384335\n",
      "-0.15631035494090129\n",
      "-0.16254277908797654\n",
      "-0.005967008904885107\n",
      "0.03434027729030609\n",
      "0.12776348134798354\n",
      "0.09045125390365882\n",
      "0.12447135526248232\n",
      "-0.000551706660877116\n",
      "0.35828875231434126\n",
      "0.29662544148549325\n",
      "0.3296464193443969\n",
      "-0.2351200627727401\n",
      "0.0009157521612599417\n",
      "1000 of 1000 iterations completed.\n",
      "-0.056831172830334786\n",
      "Profit over 1000 random race markets = 3.4729132823821462. 1204 pairs found, 118 pairs traded and 157 pairs trades made. 74 of 157 were profitable.\n"
     ]
    }
   ],
   "source": [
    "#CLEAN VERSION WITH LESS STATS\n",
    "\n",
    "# Stats\n",
    "profit = 0\n",
    "num_pairs = 0\n",
    "pairs_traded = 0\n",
    "profitable_trades = 0\n",
    "num_trades_total = 0\n",
    "#\n",
    "\n",
    "# Beginning of the Monte Carlo solution\n",
    "\n",
    "n = 1000 #number of iterations\n",
    "stake = 1 #total stake on opening side of bets\n",
    "\n",
    "for i in range(n):\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"{i+1} of {n} iterations completed.\")\n",
    "    \n",
    "    bp_t_df, lp_t_df, mid_df, log_mid = sample_dataframe()\n",
    "\n",
    "    dickey_fuller_results_df = dickey_fuller_test(log_mid)\n",
    "    \n",
    "    pairs_df = 0\n",
    "    pairs_df = race_pairs(dickey_fuller_results_df, 0.01)\n",
    "    if type(pairs_df) != pd.DataFrame: #i.e. if there are no pairs, reset to next iteration\n",
    "        continue\n",
    "    num_pairs += len(pairs_df.index)\n",
    "\n",
    "    \n",
    "    # The trading strategy code    \n",
    "    if len(pairs_df.index) < 6:  #TRADING RULE: REJECT RACES WHERE MORE THAN 5 PAIRS ARE FOUND\n",
    "        for id_id in pairs_df['pair']:\n",
    "\n",
    "            # PAIR DATAFRAME SETUP\n",
    "            \n",
    "            # Grabbing identifying details for the given pair\n",
    "            pair_index = pairs_df.index[pairs_df['pair'] == id_id].item()\n",
    "            pair_ids = pairs_df['pair'].loc[pair_index]\n",
    "            pair_coef = pairs_df['coef'].loc[pair_index]\n",
    "            pair_cv = pairs_df['critical_value'].loc[pair_index]\n",
    "            horse_a = pair_ids.split(\"_\", 1)[0]\n",
    "            horse_b = pair_ids.split(\"_\", 1)[1]\n",
    "            # Creating the prices dataframe for the given pair\n",
    "            pair_df = bp_t_df[[horse_a, horse_b]] #prices dataframe\n",
    "            pair_df = pd.concat([pair_df, lp_t_df[[horse_a, horse_b]]], axis=1) #with lay prices as well\n",
    "            pair_df.columns = [horse_a + \"_bp\", horse_b + \"_bp\", horse_a + \"_lp\", horse_b + \"_lp\"]\n",
    "            pair_df['spread'] = mid_df[horse_a] - mid_df[horse_b]\n",
    "\n",
    "            # Creating price filters for trades and key variables\n",
    "            pair_spread_sd = np.std(pair_df['spread'][0:29], ddof = 1)\n",
    "            pair_spread_mean = pair_df['spread'][0:29].mean()\n",
    "            \n",
    "            horse_a_mean_bp = pair_df[horse_a + \"_bp\"][0:29].mean()\n",
    "            horse_a_mean_lp = pair_df[horse_a + \"_lp\"][0:29].mean()\n",
    "            horse_a_mean_mid = (horse_a_mean_bp + horse_a_mean_lp) / 2\n",
    "            horse_b_mean_bp = pair_df[horse_b + \"_bp\"][0:29].mean()\n",
    "            horse_b_mean_lp = pair_df[horse_b + \"_lp\"][0:29].mean()\n",
    "            horse_b_mean_mid = (horse_b_mean_bp + horse_b_mean_lp) / 2\n",
    "            \n",
    "        \n",
    "            # TRADING STRATEGY SETUP\n",
    "            # Trade indicators     \n",
    "            \n",
    "            # Standard deviations indicator for opening and closing bets - size of deviations from mean. Bets are opened when this becomes True and close when it stops being True\n",
    "            pair_df['deviation_1sd'] = np.where(abs(pair_df['spread']) - abs(pair_spread_mean) > 1 * pair_spread_sd, 1, 0)\n",
    "\n",
    "            # The 3 / 3.5 / 4 standard deviation threshold is a bit arbitrary, but I need some threshold for whether the deviations are a bit too big and it looks like the series has lost its pair characteristics\n",
    "            pair_df['spread_too_big'] = np.where(abs(pair_df['spread']) - abs(pair_spread_mean) > 3.5 * pair_spread_sd, 1, 0) \n",
    "\n",
    "            # Abort pair if price of one horse on average is over some threshold\n",
    "            if (horse_a_mean_mid > 50) or (horse_b_mean_mid > 50):\n",
    "                continue\n",
    "                \n",
    "            # Close a bet if the deviation gets too big = dont bet on a pair if too many values are too far from the mean spread\n",
    "            # Can't think of a better way to do this without messing up my open close setup\n",
    "            if sum(pair_df['spread_too_big']) > 20:\n",
    "                continue\n",
    "             \n",
    "            # Trade open and close points\n",
    "            \n",
    "            #STRATEGY 3: SPREAD PROFIT SPREAD HEDGE TO EXPECTED PRICES\n",
    "            pair_df['profit_pc_hedge_to_expected'] = pair_df.apply(lambda x: bet_prof_pc_2(x[horse_a + \"_bp\"], x[horse_a + \"_lp\"], x[horse_b + \"_bp\"], x[horse_b + \"_lp\"], x['spread'], pair_spread_mean, 1, 1), axis=1)\n",
    "            \n",
    "            # Create open and close dictionary, opening bets where the prior column passes 1.5, and closing out the next time its less than 0.5, greater than 10 or the end of the df\n",
    "            openidx = 0\n",
    "            closeidx = 0\n",
    "            open_close_dict_3 = {'open' : [], 'close' : []}\n",
    "            idx0 = 30\n",
    "            stoploss = 0\n",
    "            breakiteration = 0\n",
    "            while 30 <= idx0 < 60 and stoploss == 0 and breakiteration == 0:\n",
    "                try: openidx = pair_df[idx0:][pair_df['profit_pc_hedge_to_expected'][idx0:] > 2].index[0] #find first value above 1.5\n",
    "                except: \n",
    "                    breakiteration = 1\n",
    "                try:\n",
    "                    try: \n",
    "                        closeidx = pair_df[openidx + 1:][pair_df['profit_pc_hedge_to_expected'][openidx + 1:] > 15].index[0] #stop loss\n",
    "                        stoploss = 1 # break while loop\n",
    "                    except: closeidx = pair_df[openidx + 1:][pair_df['profit_pc_hedge_to_expected'][openidx + 1:] < 0.5].index[0] #find the index of the first value below 0.5 after the first above X\n",
    "                except: closeidx = 59 #if there is now close index before 59, set it equal to 59. code wont get here unless there was an open index\n",
    "                if openidx != 0:\n",
    "                    open_close_dict_3['open'].append(openidx)\n",
    "                    open_close_dict_3['close'].append(closeidx)\n",
    "                    idx0 = closeidx + 1 #redo, starting from the index after the last close  \n",
    "            if breakiteration == 1:\n",
    "                continue #go on to next pair if no trading points are found\n",
    "            \n",
    "            \n",
    "            \n",
    "            # STRATEGY 2: BETTING BASED ON HEDGE PROFITS TO MEAN PRICES\n",
    "            # Percentage deviation of each horse from its mean price for stake weighting\n",
    "            pair_df['a_deviation_from_mean'] = 100 * (mid_df[horse_a] - (horse_a_mean_mid)) / horse_a_mean_mid\n",
    "            pair_df['b_deviation_from_mean'] = 100 * (mid_df[horse_b] - (horse_b_mean_mid)) / horse_b_mean_mid\n",
    "            pair_df['weight_a'] = abs(pair_df['a_deviation_from_mean']) / (abs(pair_df['a_deviation_from_mean']) + abs(pair_df['b_deviation_from_mean']))\n",
    "            pair_df['weight_b'] = abs(pair_df['b_deviation_from_mean']) / (abs(pair_df['a_deviation_from_mean']) + abs(pair_df['b_deviation_from_mean']))   \n",
    "            \n",
    "            # Profit to mean indicator for opening bets. Then create a variable equal to 1 (else 0) if a hedge starting at the price and closing at the mean would give an X% margin\n",
    "            pair_df['profit_pc_hedge_to_mean'] = pair_df.apply(lambda x: bet_prof_pc(x[horse_a + \"_bp\"], x[horse_a + \"_lp\"], x[horse_b + \"_bp\"], x[horse_b + \"_lp\"], x['spread'], x['weight_a'], x['weight_b']), axis=1)\n",
    "            \n",
    "            # Create open and close dictionary, opening bets where the prior column passes 1.5, and closing out the next time its less than 0.5, greater than 10 or the end of the df\n",
    "            openidx = 0\n",
    "            closeidx = 0\n",
    "            open_close_dict_2 = {'open' : [], 'close' : []}\n",
    "            idx0 = 30\n",
    "            stoploss = 0\n",
    "            breakiteration = 0\n",
    "            while 30 <= idx0 < 60 and stoploss == 0 and breakiteration == 0:\n",
    "                try: openidx = pair_df[idx0:][pair_df['profit_pc_hedge_to_mean'][idx0:] > 1.5].index[0] #find first value above 1.5\n",
    "                except: \n",
    "                    breakiteration = 1\n",
    "                try:\n",
    "                    try: \n",
    "                        closeidx = pair_df[openidx + 1:][pair_df['profit_pc_hedge_to_mean'][openidx + 1:] > 10].index[0] #stop loss\n",
    "                        stoploss = 1 # break while loop\n",
    "                    except: closeidx = pair_df[openidx + 1:][pair_df['profit_pc_hedge_to_mean'][openidx + 1:] < 0.5].index[0] #find the index of the first value below 0.5 after the first above X\n",
    "                except: closeidx = 59 #if there is now close index before 59, set it equal to 59. code wont get here unless there was an open index\n",
    "                if openidx != 0:\n",
    "                    open_close_dict_2['open'].append(openidx)\n",
    "                    open_close_dict_2['close'].append(closeidx)\n",
    "                    idx0 = closeidx + 1 #redo, starting from the index after the last close  \n",
    "            if breakiteration == 1:\n",
    "                continue #go on to next pair if no trading points are found\n",
    "                \n",
    "                         \n",
    "            \n",
    "            \n",
    "            # STRATEGY 1: BETTING BASED ON CURRENT SPREAD DEVIATIONS FROM MEAN\n",
    "            # Gives = 1 to open a bet, and -1 to close a bet for the True/False setup - opening upon change to True, closing on change to False\n",
    "            pair_df['open_close_bets'] = pair_df['deviation_1sd'].diff() \n",
    "            # Gives rows where bets are open value of 0.5\n",
    "            pair_df['open_close_bets'] = np.where((pair_df['deviation_1sd'] == 1) & (pair_df['open_close_bets'] == 0), 0.5, pair_df['open_close_bets'])\n",
    "            # Open at 30 if a bet should be ongoing\n",
    "            pair_df['open_close_bets'] = np.where((pair_df.index == 30) & (pair_df['open_close_bets'] == 0.5), 1, pair_df['open_close_bets'])            \n",
    "            # Close at 59 if the last bet doesnt close before\n",
    "            pair_df['open_close_bets'] = np.where((pair_df.index == len(pair_df.index) - 1) & (pair_df['open_close_bets'] == 0.5), -1, pair_df['open_close_bets'])\n",
    "            # Collect open and close indices. There is definitely a better way to do this if I can get the pair_df indices in the list rather than grabbing indices from a new np list\n",
    "            open_bets_idx = list(np.where(pair_df['open_close_bets'][30:] == 1)[0] + 30)\n",
    "            close_bets_idx = list(np.where(pair_df['open_close_bets'][30:] == -1)[0] + 30)\n",
    "            # Create dictionary of pair open and close indices\n",
    "            open_close_dict = {'open' : open_bets_idx, 'close' : close_bets_idx}\n",
    "            # Dont do bets if there are no indices to open or close\n",
    "            if (len(open_bets_idx) == 0) or (len(close_bets_idx) == 0):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # BETS            \n",
    "\n",
    "            # Change dictionary depending on strategy\n",
    "            for o, c in zip(open_close_dict_3['open'], open_close_dict_2['close']):\n",
    "                # Stakes for A and B weighted based on deviation to mean\n",
    "                stake_a_o = pair_df['weight_a'].iloc[o] * stake\n",
    "                stake_b_o = pair_df['weight_b'].iloc[o] * stake                \n",
    "                \n",
    "                # Add profits, return stakes on the other side of the bets (for rate of return)\n",
    "                win_side_a, win_side_b, stake_a_c, stake_b_c = bet(o, c, stake_a_o, stake_b_o)\n",
    "                \n",
    "                # Stats\n",
    "                profit += win_side_a + win_side_b\n",
    "                print(win_side_a + win_side_b)\n",
    "                if (win_side_a + win_side_b) > 0:\n",
    "                    profitable_trades += 1\n",
    "            \n",
    "            # Stats\n",
    "            num_trades_total += len(open_close_dict_2['open'])\n",
    "            pairs_traded += 1\n",
    "                \n",
    "\n",
    "print(f\"Profit over {n} random race markets = {profit}. {num_pairs} pairs found, {pairs_traded} pairs traded and {num_trades_total} pairs trades made. {profitable_trades} of {num_trades_total} were profitable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair_df[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #VERSION WITH A LOAD MORE STATS COLLECTED\n",
    "\n",
    "# ########## stats\n",
    "# profit = 0\n",
    "# num_pairs = 0\n",
    "# pairs_traded = 0\n",
    "# num_trades_total = 0\n",
    "# results_dict = {'pair' : [], 'mean_spread' : [], 'final_spread' : [], 'pair_cv' : [], 'pair_coef' : [], 'pairs_in_race' : [],\n",
    "#                 'num_trades' : [], 'profitable_trades' : [], 'losing_trades' : [], 'pc_trades_prof' : [], 'pair_profit' : [], 'pair_profits_list' : []}\n",
    "# ##########\n",
    "\n",
    "# # Beginning of the Monte Carlo solution\n",
    "\n",
    "# n = 200 #number of iterations\n",
    "# k = 5 #number of 2-minute periods trade is kept open (i.e. time expected for mean reversion to occur). this is used in the bet() function below\n",
    "\n",
    "# for i in range(n):\n",
    "#     if (i + 1) % 100 == 0:\n",
    "#         print(f\"{i+1} of {n} iterations completed.\")\n",
    "    \n",
    "#     bp_t_df, lp_t_df, mid_df, log_mid = sample_dataframe()\n",
    "\n",
    "#     dickey_fuller_results_df = dickey_fuller_test(log_mid)\n",
    "    \n",
    "#     pairs_df = 0\n",
    "#     pairs_df = race_pairs(dickey_fuller_results_df, 0.01)\n",
    "#     if type(pairs_df) != pd.DataFrame: #i.e. if there are no pairs, reset to next iteration\n",
    "#         continue\n",
    "    \n",
    "#     # The trading strategy code    \n",
    "#     if len(pairs_df.index) < 6:  #TRADING RULE: REJECT RACES WHERE MORE THAN 5 PAIRS ARE FOUND\n",
    "#         for id_id in pairs_df['pair']:\n",
    "\n",
    "#             # Grabbing identifying details for the given pair\n",
    "#             pair_index = pairs_df.index[pairs_df['pair'] == id_id].item()\n",
    "#             pair_ids = pairs_df['pair'].loc[pair_index]\n",
    "#             pair_coef = pairs_df['coef'].loc[pair_index]\n",
    "#             pair_cv = pairs_df['critical_value'].loc[pair_index]\n",
    "#             horse_a = pair_ids.split(\"_\", 1)[0]\n",
    "#             horse_b = pair_ids.split(\"_\", 1)[1]\n",
    "#             # Creating the prices dataframe for the given pair\n",
    "#             pair_df = bp_t_df[[horse_a, horse_b]] #prices dataframe\n",
    "#             pair_df = pd.concat([pair_df, lp_t_df[[horse_a, horse_b]]], axis=1) #with lay prices as well\n",
    "#             pair_df.columns = [horse_a + \"_bp\", horse_b + \"_bp\", horse_a + \"_lp\", horse_b + \"_lp\"]\n",
    "#             pair_df['spread'] = mid_df[horse_a] - mid_df[horse_b]\n",
    "\n",
    "#             #Filtering criteria\n",
    "#             pair_spread_sd = np.std(pair_df['spread'][0:29], ddof = 1)\n",
    "#             pair_spread_mean = pair_df['spread'][0:29].mean()\n",
    "#             pair_df['deviation_2sd'] = np.where(abs(pair_df['spread']) - abs(pair_spread_mean) > 2 * pair_spread_sd, True, False)\n",
    "#             pair_df['deviation_4sd'] = np.where(abs(pair_df['spread']) - abs(pair_spread_mean) > 4 * pair_spread_sd, True, False)            \n",
    "\n",
    "#             #Create a dataframe where each row \n",
    "#             #If there is sufficient deviatiion anywhere, make the trades\n",
    "#             open_trade_df = pair_df[pair_df['deviation_2sd'] == True].loc[30:] #only data after the first 30 periods\n",
    "#             open_trade_df.drop_duplicates(inplace=True)\n",
    "\n",
    "#             ########## stats\n",
    "#             if len(open_trade_df.index) > 0:\n",
    "#                 pairs_traded += 1\n",
    "#             num_trades_pair = 0\n",
    "#             profitable_trades_pair = 0\n",
    "#             losing_trades_pair = 0\n",
    "#             pair_profit = 0\n",
    "#             pair_profits_list = []\n",
    "#             ##########\n",
    "\n",
    "#             #if there are indexs at which to make trades and trades can be completed, cycle through them\n",
    "#             #TRADING RULE: IGNORE HORSES WHO ARE TRADING WITH SPREAD OF 3 SD OR GREATER THAN MEAN (to avoid horses who have deviated too much)    \n",
    "#             while (len(open_trade_df.index) > 0) and ((open_trade_df.index[0] + k) < 59) and (open_trade_df['deviation_4sd'].loc[open_trade_df.index[0]] == False):\n",
    "                \n",
    "                \n",
    "#                 open_trade_idx = open_trade_df.index[0]\n",
    "#                 win_side_a, win_side_b = bet(open_trade_idx, k)\n",
    "\n",
    "#                 #removes traded line from open_trade_df #+ 1 period gap between trades on a given pair. #edit this to alter the repetition of trades\n",
    "#                 open_trade_df = open_trade_df.loc[open_trade_idx + k + 1:] \n",
    "                \n",
    "\n",
    "#                 ########## stats\n",
    "#                 profit += win_side_a + win_side_b\n",
    "#                 num_trades_total += 1\n",
    "#                 num_trades_pair += 1\n",
    "#                 if (win_side_a + win_side_b) > 0:\n",
    "#                     profitable_trades_pair += 1\n",
    "#                 else:\n",
    "#                     losing_trades_pair += 1\n",
    "#                 pair_profit += win_side_a + win_side_b\n",
    "#                 pair_profits_list.append(round(win_side_a + win_side_b,2))\n",
    "#                 ##########    \n",
    "\n",
    "#             ########## stats\n",
    "#             num_pairs += 1\n",
    "#             results_dict['pair'].append(id_id)\n",
    "#             results_dict['mean_spread'].append(pair_spread_mean)\n",
    "#             results_dict['final_spread'].append(pair_df['spread'].loc[59])\n",
    "#             results_dict['pair_cv'].append(pair_cv)\n",
    "#             results_dict['pair_coef'].append(pair_coef)\n",
    "#             results_dict['pairs_in_race'].append(len(pairs_df.index))\n",
    "#             results_dict['num_trades'].append(num_trades_pair) \n",
    "#             results_dict['profitable_trades'].append(profitable_trades_pair) \n",
    "#             results_dict['losing_trades'].append(losing_trades_pair) \n",
    "#             try: results_dict['pc_trades_prof'].append((profitable_trades_pair / num_trades_pair) * 100)\n",
    "#             except: results_dict['pc_trades_prof'].append(0)\n",
    "#             results_dict['pair_profit'].append(pair_profit) \n",
    "#             results_dict['pair_profits_list'].append(pair_profits_list)\n",
    "#             #average profit\n",
    "#             #number of horses in race\n",
    "#             ##########\n",
    "    \n",
    "#     #else: continue #move on to next race day if there are no stationary series  \n",
    "\n",
    "# results_df = pd.DataFrame(results_dict)\n",
    "# results_df = results_df[results_df['num_trades'] > 0].copy()\n",
    "# #results_df.to_csv(data_dir.parents[0] / 'pairs_trade_results.csv', index = False, header=True)\n",
    "\n",
    "# profitable_trades_total = results_df['profitable_trades'].sum()       \n",
    "# print(f\"Profit over {n} random race markets = {profit}. {num_pairs} pairs found, {pairs_traded} pairs traded and {num_trades_total} pairs trades made. {profitable_trades_total} of {num_trades_total} were profitable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
